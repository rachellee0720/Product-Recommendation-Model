{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be2b89e6",
   "metadata": {},
   "source": [
    "# **Product Recommendation Model: DNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22168b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install torch torchvision torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.set_printoptions(precision=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6765ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from behavior2vec import behavior2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print('file deleted')\n",
    "    else:\n",
    "        print(\"Can not delete the file as it doesn't exists\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "621f0d6b",
   "metadata": {},
   "source": [
    "# Convert browsing behaviors of customers into vectors\n",
    "1. consider the maximun duration of a working session as one hour, and a session means the amount of time a customer spends on the website.\n",
    "\n",
    "2. collect the behavioral data of all customers in the past year, and organize data into every row representing all behaviors of a customer in a session. (the results are stored at variable \"file\" below)\n",
    "\n",
    "3. train Behavior2Vec model to convert the behavioral data into vectors which model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_data.txtï¼ševery row of this file represents the behavior of one customer within one hour \n",
    "# file = ['view-product_ID1 view-product_ID2\\n', 'view-product_ID3 leave-product_ID3\\n', ...]\n",
    "file = open('session_data.txt', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1099399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train behavior2vec model\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "model = behavior2vec.Behavior2Vec()\n",
    "file_name = 'session_data.txt' \n",
    "model.train(file_name, size=32)\n",
    "\n",
    "model_name = \"Behavior2Vec_20221017.model\"\n",
    "remove_file(model_name)\n",
    "model.full_model.save(model_name)\n",
    "\n",
    "print('Time: ', datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload behavior2vec model \n",
    "# behavior_embedding = {'view':[x1, x2, ..., x32], ...} -> embedding of customers' behaviors\n",
    "# action_product_embedding = {'view':{'product ID1':[x1, x2, ..., x32], 'product ID2':[x1, x2, ..., x32]},\n",
    "#                             'add_cart':{...}} -> embedding of each product of each behavior\n",
    "behavior_model = behavior2vec.Behavior2Vec()\n",
    "behavior_model.full_model = Word2Vec.load(\"Behavior2Vec_20221017.model\")\n",
    "behavior_model.behavior_embeddings = behavior_model._gen_behavior_embedding()\n",
    "behavior_embedding = behavior_model._gen_avg_behavior_embeddings(behavior_model.behavior_embeddings)\n",
    "product_embedding = behavior_model._gen_item_embeddings()\n",
    "action_product_embedding = behavior_model.behavior_embeddings\n",
    "\n",
    "with open('product_embedding.pkl', 'wb') as f:\n",
    "    pickle.dump(product_embedding, f)\n",
    "with open('action_product_embedding.pkl', 'wb') as f:\n",
    "    pickle.dump(action_product_embedding, f)\n",
    "with open('behavior_embedding.pkl', 'wb') as f:\n",
    "    pickle.dump(behavior_embedding, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a833ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_size = the dimension of action_product_embedding\n",
    "vector_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = list(action_product_embedding.keys())\n",
    "act_prod_2_index = {} # ex. 'view-01':0\n",
    "count = 0\n",
    "# index_2_act_prod[0] = action_product_embedding['view']['01'] = [x1, x2, ..., x32]\n",
    "index_2_act_prod = np.zeros(shape=(len(action)*len(action_product_embedding['view']), vector_size))\n",
    "\n",
    "for i in action:\n",
    "    for j in action_product_embedding[i].keys():\n",
    "        act_prod_2_index[i+'-'+j] = count\n",
    "        index_2_act_prod[count] = action_product_embedding[i][j]\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36464527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information of taiwanese products\n",
    "prod_tw_active = pd.read_csv('tw_prod_active.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_product = np.array(list(action_product_embedding['view'].keys()))\n",
    "prod_2_index = {} # ex. 'product ID1': 0\n",
    "index_2_prod = np.zeros((vector_size, all_product.shape[0])) # dimension = (32, 6667)\n",
    "# index_2_prod[:, 0] = the embedding of product ID1\n",
    "index_2_prod_list = []\n",
    "count = 0\n",
    "for i in all_product:\n",
    "    prod_2_index[i] = count\n",
    "    index_2_prod_list.append(i)\n",
    "    index_2_prod[:, count] = np.mean(product_embedding[i].reshape(-1, vector_size), axis=0)\n",
    "    count += 1\n",
    "index_2_prod = torch.from_numpy(index_2_prod).float()\n",
    "norm_product_vector = (index_2_prod/index_2_prod.norm(dim=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a413837",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "1. use behavioral data of two months before the expected advertising time point as model's input.\n",
    "\n",
    "2. last-viewed product is the model's prediction target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_raw_data.csv') \n",
    "valid_df = pd.read_csv('valid_raw_data.csv') \n",
    "test_df = pd.read_csv('test_raw_data.csv') \n",
    "print(train_df.shape, valid_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafcf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing: averaging the vectors that represent all behaviors of a customer within two months\n",
    "def preprocessing(data):\n",
    "    \n",
    "    data['act_prod'] = data['action']+'-'+data['product_oid'].astype(str)\n",
    "    data['act_prod_index'] = data['act_prod'].map(act_prod_2_index).fillna(len(act_prod_2_index)).astype(int)\n",
    "\n",
    "    data = data[data['act_prod_index'] != len(act_prod_2_index)]\n",
    "    \n",
    "    data_act_prod = data.groupby(['adtech_user_id'])['act_prod_index'].apply(list).reset_index()\n",
    "    data_product = data.groupby(['adtech_user_id'])['product_oid'].apply(list).reset_index()\n",
    "    data1 = data_act_prod.merge(data_product, how='inner', on='adtech_user_id')\n",
    "\n",
    "    data1[\"x_length\"] = data1[\"act_prod_index\"].apply(lambda x:len(x))\n",
    "    data1 = data1[data1['x_length']>1]\n",
    "    data1['y'] = data1['product_oid'].apply(lambda x:x[-1]).astype(str).map(prod_2_index)\n",
    "    \n",
    "    data1['x_embedding'] = data1['act_prod_index'].apply(lambda x:np.mean(index_2_act_prod[x[:-1]], axis=0))\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8bbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.datetime.now()\n",
    "train_df1 = preprocessing(train_df)\n",
    "valid_df1 = preprocessing(valid_df)\n",
    "test_df1 = preprocessing(test_df)\n",
    "print(train_df1.shape, valid_df1.shape, test_df1.shape)\n",
    "print(datetime.datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(data1):\n",
    "    df = data1[['adtech_user_id', 'x_embedding', 'y']]\n",
    "    df_column = ['x_'+str(i) for i in range(vector_size)]\n",
    "    df[df_column] = pd.DataFrame(df.x_embedding.tolist(), index= df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09181cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = model_input(train_df1)\n",
    "valid_data = model_input(valid_df1)\n",
    "test_data = model_input(test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc2724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train_dnn_data.csv', index=False)\n",
    "valid_data.to_csv('valid_dnn_data.csv', index=False)\n",
    "test_data.to_csv('test_dnn_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7fdb95f",
   "metadata": {},
   "source": [
    "# Deep Neural Network (DNN)\n",
    "1. build the dataset, dataloader and dnn model.\n",
    "\n",
    "2. dnn model's output is a 32-dimensional vector which represents the product that the model thinks the customer wants to see next.\n",
    "\n",
    "3. compute the cosine similarity between model's output and every product vector to find products that match model's prediction.\n",
    "\n",
    "4. sort by the similarity score from highest to lowest to get the recommended product list for a specific customer.\n",
    "\n",
    "5. use cross entropy loss and accuracy function defined below to evaluate model's performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device {device}.')\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1115\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dnn_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, device):\n",
    "          self.x = torch.tensor(np.array(data.iloc[:,3:])).to(device)\n",
    "          self.y = torch.tensor(np.array(data.iloc[:,2])).to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return  self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_dnn_data.csv')\n",
    "valid_data = pd.read_csv('valid_dnn_data.csv')\n",
    "test_data = pd.read_csv('test_dnn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "batch_size = 512\n",
    "train_loader = torch.utils.data.DataLoader(dnn_dataset(train_data, device), batch_size=batch_size, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dnn_dataset(valid_data, device), batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dnn_dataset(test_data, device), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c803d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's structure\n",
    "class first_stage(nn.Module):\n",
    "    def __init__(self, start_embedding_dim):\n",
    "        super(first_stage, self).__init__()\n",
    "        self.fc1 = nn.Linear(start_embedding_dim, 128) \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "\n",
    "    def forward(self, behavior_embedding):\n",
    "        r = F.relu(self.fc1(behavior_embedding.float()))\n",
    "        r = F.relu(self.fc2(r))\n",
    "        r = F.relu(self.fc3(r))\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the product that customer actually sees next is in the top 10 of recommended product list, \n",
    "# then append 1 into acc_list, it means model's prediction is correct, otherwise, append 0 into acc_list.\n",
    "def accuracy(top_k, y, cosine_sim):\n",
    "    count = 0\n",
    "    acc_list = []\n",
    "\n",
    "    recommend = torch.topk(cosine_sim, top_k)[1]\n",
    "    for i in y:\n",
    "        if i in recommend[count]:\n",
    "            acc_list.append(1)\n",
    "        else:\n",
    "            acc_list.append(0)\n",
    "        count += 1\n",
    "    return acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697521b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, index_2_prod, norm_product_vector, loss_func, optimizer, data_size, epoch, top_k):   \n",
    "\n",
    "    total_loss = 0\n",
    "    batch_loss = []\n",
    "    acc_list = []\n",
    "    \n",
    "    model.train()    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        out = model(x)\n",
    "        out_1 = torch.mm(out, index_2_prod)\n",
    "        \n",
    "        loss = loss_func(out_1, y)\n",
    "        cpu_loss = loss.detach().cpu().item() \n",
    "        batch_loss.append(cpu_loss/y.shape[0])        \n",
    "        total_loss += cpu_loss\n",
    " \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute cosine similarity\n",
    "        out_2 = out / out.norm(dim=1)[:,None]\n",
    "        cosine_sim = torch.mm(out_2, norm_product_vector)\n",
    "        acc_list += accuracy(top_k, y, cosine_sim)\n",
    "        gc.collect()\n",
    "        \n",
    "    epoch_loss = (total_loss/data_size)\n",
    "    acc =  np.sum(acc_list)/len(acc_list)\n",
    "    print(f'train epoch: {epoch + 1}, train loss: {epoch_loss}, train accuracy: {acc}')\n",
    "\n",
    "    return epoch_loss, batch_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid(model, loader, index_2_prod, norm_product_vector, loss_func, data_size, epoch, top_k):   \n",
    "\n",
    "    total_loss = 0\n",
    "    batch_loss = []\n",
    "    acc_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        out = model(x)\n",
    "\n",
    "        out_1 = torch.mm(out, index_2_prod)\n",
    "        cpu_loss = loss_func(out_1, y).detach().cpu().item()  \n",
    "        total_loss += cpu_loss\n",
    "        batch_loss.append(cpu_loss/y.shape[0])\n",
    "        \n",
    "\n",
    "        out_2 = out / out.norm(dim=1)[:,None]\n",
    "        cosine_sim = torch.mm(out_2, norm_product_vector)\n",
    "        acc_list += accuracy(top_k, y, cosine_sim)\n",
    "    \n",
    "    epoch_loss = (total_loss/data_size)\n",
    "    # calculate the accuracy rate\n",
    "    acc =  np.sum(acc_list)/len(acc_list)\n",
    "    print(f'valid epoch: {epoch + 1}, valid loss: {epoch_loss}, valid accuracy: {acc}')\n",
    "    \n",
    "    return epoch_loss, batch_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prediction(model, loader, norm_product_vector, top_k):\n",
    "    \n",
    "    pred = torch.tensor([])\n",
    "    acc_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        out = model(x)\n",
    "        # compute cosine similarity\n",
    "        out = out / out.norm(dim=1)[:,None]\n",
    "        cosine_sim = torch.mm(out, norm_product_vector)\n",
    "        pred = torch.cat((pred, cosine_sim.detach().cpu()), 0)\n",
    "        acc_list += accuracy(top_k, y, cosine_sim)\n",
    "            \n",
    "    return pred, np.sum(acc_list)/len(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "def save_ckpt(score, epoch, model, optim, model_path):\n",
    "    remove_file(model_path)\n",
    "    torch.save({'epoch': epoch+1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optim_state_dict': optim.state_dict(),\n",
    "                'score': score}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16894273",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "best_score = 0.0\n",
    "min_loss = 100000000\n",
    "patience = 40\n",
    "trigger_times = 0\n",
    "top_k = 10\n",
    "reload = True\n",
    "model_path = 'best_model.pth.tar'\n",
    "lr = 0.005\n",
    "performance_dict = {'train_epoch_loss':[], 'valid_epoch_loss':[], \n",
    "                    'train_epoch_acc':[], 'valid_epoch_acc':[],\n",
    "                    'train_batch_loss':[], 'valid_batch_loss':[]}\n",
    "\n",
    "model = first_stage(vector_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "if reload == True:\n",
    "    ckpt = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    optimizer.load_state_dict(ckpt['optim_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('performance_dict.pkl', 'rb') as f:\n",
    "    performance_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every epoch: 1 training + 1 validation\n",
    "start=datetime.datetime.now()\n",
    "\n",
    "for epoch_num in range(epoch):\n",
    "    print(epoch_num)\n",
    "    epoch_train_loss, batch_train_loss, epoch_train_acc = \\\n",
    "    train(model, train_loader, index_2_prod.to(device), norm_product_vector.to(device), \n",
    "          loss_func, optimizer, train_data.shape[0], epoch_num, top_k)\n",
    "  \n",
    "    epoch_val_loss, batch_val_loss, epoch_val_acc = \\\n",
    "    valid(model, val_loader, index_2_prod.to(device), norm_product_vector.to(device), \n",
    "          loss_func, valid_data.shape[0], epoch_num, top_k)\n",
    "\n",
    "  \n",
    "    if epoch_val_acc > best_score:\n",
    "        save_ckpt(epoch_val_acc, epoch_num, model, optimizer, model_path)\n",
    "        best_score = epoch_val_acc\n",
    "  \n",
    "    performance_dict['train_epoch_loss'].append(epoch_train_loss)\n",
    "    performance_dict['valid_epoch_loss'].append(epoch_val_loss)\n",
    "    performance_dict['train_epoch_acc'].append(epoch_train_acc)\n",
    "    performance_dict['valid_epoch_acc'].append(epoch_val_acc)\n",
    "    performance_dict['train_batch_loss'] += batch_train_loss\n",
    "    performance_dict['valid_batch_loss'] += batch_val_loss\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch_val_loss >= min_loss:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "    else:\n",
    "        trigger_times = 0\n",
    "        min_loss = epoch_val_loss\n",
    "    \n",
    "print(datetime.datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fc00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and accuracy rate\n",
    "def plot(train_data, valid_data, title, label_name, x_label, y_label, fig_name):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.plot(range(len(train_data)), train_data, 'o-', c='blue', alpha=0.3, label='train - '+ label_name, linewidth=3)\n",
    "    plt.plot(range(len(valid_data)), valid_data, 'o-', c='orange', alpha=0.7, label='valid - '+ label_name, linewidth=3)\n",
    "    plt.xlabel(x_label, fontsize=15)\n",
    "    plt.ylabel(y_label, fontsize=20)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.legend(prop = {'size':15})\n",
    "    plt.grid()\n",
    "    plt.savefig(fig_name + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(performance_dict['train_epoch_loss'], performance_dict['valid_epoch_loss'],  'train & valid epoch loss', 'loss', 'epoch number', 'loss', 'train_valid_epoch_loss')\n",
    "plot(performance_dict['train_epoch_acc'], performance_dict['valid_epoch_acc'],  'train & valid epoch accuracy', 'accuracy', 'epoch number', 'accuracy', 'train_valid_epoch_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29762307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "optimizer.load_state_dict(ckpt['optim_state_dict'])\n",
    "pred, test_acc = prediction(model, test_loader, norm_product_vector.to(device), top_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "70b8d9a4f79ce26a5c42f30717429203496a780e9421e71e46698b8c787fce83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
